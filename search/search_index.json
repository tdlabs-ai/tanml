{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"TanML: Automated Model Validation Toolkit for Tabular Machine Learning","text":"<p>TanML bridges the gap between data science tools (for building models) and governance requirements (for validating them). It's not just an ML library\u2014it's a validation workflow with built-in documentation.</p> <ul> <li>Status: Beta (<code>0.x</code>)</li> <li>License: MIT</li> <li>Python: 3.8\u20133.13</li> <li>OS: Linux / macOS / Windows (incl. WSL)</li> </ul>"},{"location":"#why-tanml","title":"Why TanML?","text":"<ul> <li>End-to-end workflow: Data Profiling \u2192 Preprocessing \u2192 Feature Ranking \u2192 Model Development \u2192 Evaluation \u2192 Reports\u2014all in one UI.</li> <li>Audit-ready Word reports: Generate editable .docx documents for stakeholders and compliance reviews.</li> <li>Built for regulated industries: Designed for MRM, credit risk, insurance, and SR 11-7 contexts.</li> <li>No code required: Fully UI-driven\u2014no Python knowledge needed.</li> <li>Robust evaluation: Drift detection, stress testing, SHAP explainability, cluster coverage.</li> <li>Works with your stack: scikit-learn, XGBoost, LightGBM, CatBoost.</li> </ul>"},{"location":"#install","title":"Install","text":"<p>We strongly recommend using a virtual environment to isolate dependencies:</p> <pre><code># Create and activate virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # Linux/Mac\n# .venv\\Scripts\\activate   # Windows\n\n# Install TanML\npip install tanml\n</code></pre>"},{"location":"#quick-start-ui","title":"Quick Start (UI)","text":"<pre><code>tanml ui\n</code></pre> <ul> <li>Opens at http://127.0.0.1:8501</li> <li>Upload limit ~2 GB (preconfigured)</li> <li>Telemetry disabled by default</li> </ul>"},{"location":"#optional-cli-flags","title":"Optional CLI Flags","text":"<p>Most users just run <code>tanml ui</code>. These help on teams/servers:</p> <pre><code># Share on LAN\ntanml ui --public\n\n&gt; [!WARNING]\n&gt; Using `--public` makes the UI accessible to anyone on your network. Only use this on trusted networks (like a VPN or secure office LAN) and never on public Wi-Fi.\n\n# Different port\ntanml ui --port 9000\n\n# Headless (server/CI; no auto-open browser)\ntanml ui --headless\n\n# Larger limit (e.g., 2 GB)\ntanml ui --max-mb 2048\n</code></pre> <p>Env var equivalents (Linux/macOS bash):</p> <pre><code>TANML_SERVER_ADDRESS=0.0.0.0 TANML_PORT=9000 TANML_MAX_MB=2048 tanml ui\n</code></pre> <p>Windows PowerShell:</p> <pre><code>$env:TANML_SERVER_ADDRESS=\"0.0.0.0\"; $env:TANML_PORT=\"9000\"; $env:TANML_MAX_MB=\"2048\"; tanml ui\n</code></pre> <p>Defaults: address <code>127.0.0.1</code>, port <code>8501</code>, limit <code>2048 MB</code>, telemetry OFF.</p>"},{"location":"#reports","title":"Reports","text":"<p>TanML generates audit-ready Word reports (.docx) programmatically:</p> <ul> <li>Model Development Report \u2014 Cross-validation metrics, diagnostics, and performance summary</li> <li>Model Evaluation Report \u2014 Train/Test comparison, drift analysis, stress testing, SHAP explainability</li> <li>Feature Power Ranking Report \u2014 Feature importance scores, correlation analysis</li> </ul> <p>Reports are generated via <code>tanml/ui/reports/generators.py</code> and exported directly from the UI.</p>"},{"location":"#data-privacy","title":"Data Privacy","text":"<ul> <li>TanML runs locally; no data is sent to external services.</li> <li>Telemetry is disabled by default (and can be forced off via <code>--no-telemetry</code>).</li> <li>Security Note: Running with the <code>--public</code> flag exposes the app to your local network. Ensure you are on a secure connection.</li> <li>UI artifacts and reports are written under <code>./tanml_runs/&lt;session&gt;/</code> in your working directory.</li> </ul>"},{"location":"#license-citation","title":"License &amp; Citation","text":"<p>License: MIT. See LICENSE. SPDX-License-Identifier: MIT</p> <p>\u00a9 2025 Tanmay Sah and Dolly Sah. You may use, modify, and distribute this software with appropriate attribution.</p>"},{"location":"#how-to-cite","title":"How to cite","text":"<p>If TanML helps your work or publications, please cite:</p> <p>Sah, T., &amp; Sah, D. (2025). TanML: Automated Model Validation Toolkit for Tabular Machine Learning [Software]. Zenodo. https://doi.org/10.5281/zenodo.17317165</p> <p>Or in BibTeX (version-agnostic):</p> <pre><code>@software{tanml_2025,\n  author       = {Sah, Tanmay and Sah, Dolly},\n  title        = {TanML: Automated Model Validation Toolkit for Tabular Machine Learning},\n  year         = {2025},\n  publisher    = {Zenodo},\n  doi          = {10.5281/zenodo.17317165},\n  url          = {https://doi.org/10.5281/zenodo.17317165},\n  license      = {MIT}\n}\n</code></pre> <p>A machine-readable citation file (<code>CITATION.cff</code>) is included for citation tools and GitHub\u2019s \u201cCite this repository\u201d button.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>We welcome contributions! Please see our CONTRIBUTING.md file on GitHub for more details.</p>"},{"location":"installation/","title":"Installation","text":"<p>TanML requires Python 3.8 or higher.</p>"},{"location":"installation/#using-pip","title":"Using pip","text":"<p>The easiest way to install TanML is using pip:</p> <pre><code>pip install tanml\n</code></pre>"},{"location":"installation/#from-source","title":"From Source","text":"<p>You can also install TanML directly from the source code:</p> <pre><code>git clone https://github.com/tdlabs-ai/tanml.git\ncd tanml\npip install -e .\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<p>To verify that TanML is installed correctly, you can run:</p> <pre><code>tanml --version\n</code></pre>"},{"location":"reference/","title":"API Reference","text":"<p>Feature drift analysis module.</p> <p>Provides PSI (Population Stability Index) and KS (Kolmogorov-Smirnov) statistics for detecting distribution shifts between train and test data.</p> Example <p>from tanml.analysis.drift import analyze_drift</p> <p>drift_results = analyze_drift(     train_df=X_train,     test_df=X_test,     numeric_cols=[\"age\", \"income\", \"score\"], )</p> <p>for col, metrics in drift_results.items():     print(f\"{col}: PSI={metrics['psi']:.3f}, KS={metrics['ks']:.3f}\")</p>"},{"location":"reference/#tanml.models.registry.ModelSpec","title":"<code>ModelSpec</code>  <code>dataclass</code>","text":"Source code in <code>tanml/models/registry.py</code> <pre><code>@dataclass(frozen=True)\nclass ModelSpec:\n    task: Task\n    import_path: str  # e.g., \"sklearn.ensemble.RandomForestClassifier\"\n    defaults: dict[str, Any] = field(default_factory=dict)\n    # UI schema: param -&gt; (type, choices_or_None, help_or_None)\n    ui_schema: dict[str, tuple[str, tuple[Any, ...] | None, str | None]] = field(\n        default_factory=dict\n    )\n    aliases: dict[str, str] = field(default_factory=dict)  # optional param alias map\n</code></pre>"},{"location":"reference/#tanml.models.registry.build_estimator","title":"<code>build_estimator(library, algo, params=None)</code>","text":"Source code in <code>tanml/models/registry.py</code> <pre><code>def build_estimator(library: str, algo: str, params: dict[str, Any] | None = None):\n    spec = get_spec(library, algo)\n    Cls = _lazy_import(spec.import_path)\n    kwargs = dict(spec.defaults)\n    if params:\n        canon = {}\n        for k, v in params.items():\n            k2 = spec.aliases.get(k, k)\n            canon[k2] = v\n        kwargs.update({k: v for k, v in canon.items() if v is not None})\n    return Cls(**kwargs)\n</code></pre>"},{"location":"reference/#tanml.models.registry.list_models","title":"<code>list_models(task=None)</code>","text":"Source code in <code>tanml/models/registry.py</code> <pre><code>def list_models(task: Task | None = None) -&gt; dict[tuple[str, str], ModelSpec]:\n    if task:\n        return {k: v for k, v in _REGISTRY.items() if v.task == task}\n    return dict(_REGISTRY)\n</code></pre>"},{"location":"reference/#tanml.models.registry.get_spec","title":"<code>get_spec(library, algo)</code>","text":"Source code in <code>tanml/models/registry.py</code> <pre><code>def get_spec(library: str, algo: str) -&gt; ModelSpec:\n    key = (library, algo)\n    if key not in _REGISTRY:\n        raise KeyError(f\"Unknown model: {library}.{algo}\")\n    return _REGISTRY[key]\n</code></pre>"},{"location":"reference/#tanml.analysis.drift.calculate_psi","title":"<code>calculate_psi(expected, actual, bins=10)</code>","text":"<p>Calculate Population Stability Index (PSI) between two distributions.</p> <p>PSI measures how much a distribution has shifted. Thresholds:     - PSI &lt; 0.1: No significant shift     - 0.1 &lt;= PSI &lt; 0.2: Moderate shift (investigate)     - PSI &gt;= 0.2: Large shift (action needed)</p> <p>Parameters:</p> Name Type Description Default <code>expected</code> <code>Series</code> <p>Expected/baseline distribution (e.g., training data)</p> required <code>actual</code> <code>Series</code> <p>Actual/new distribution (e.g., test data)</p> required <code>bins</code> <code>int</code> <p>Number of bins for discretization</p> <code>10</code> <p>Returns:</p> Type Description <code>float</code> <p>PSI value (float)</p> Source code in <code>tanml/analysis/drift.py</code> <pre><code>def calculate_psi(\n    expected: pd.Series,\n    actual: pd.Series,\n    bins: int = 10,\n) -&gt; float:\n    \"\"\"\n    Calculate Population Stability Index (PSI) between two distributions.\n\n    PSI measures how much a distribution has shifted. Thresholds:\n        - PSI &lt; 0.1: No significant shift\n        - 0.1 &lt;= PSI &lt; 0.2: Moderate shift (investigate)\n        - PSI &gt;= 0.2: Large shift (action needed)\n\n    Args:\n        expected: Expected/baseline distribution (e.g., training data)\n        actual: Actual/new distribution (e.g., test data)\n        bins: Number of bins for discretization\n\n    Returns:\n        PSI value (float)\n    \"\"\"\n    # Handle edge cases\n    expected = expected.dropna()\n    actual = actual.dropna()\n\n    if len(expected) == 0 or len(actual) == 0:\n        return np.nan\n\n    # Create bins from expected distribution\n    try:\n        _, bin_edges = np.histogram(expected, bins=bins)\n    except ValueError:\n        return np.nan\n\n    # Calculate proportions in each bin\n    expected_counts = np.histogram(expected, bins=bin_edges)[0]\n    actual_counts = np.histogram(actual, bins=bin_edges)[0]\n\n    # Convert to proportions (avoid division by zero)\n    expected_pct = expected_counts / len(expected)\n    actual_pct = actual_counts / len(actual)\n\n    # Replace zeros with small value to avoid log(0)\n    eps = 1e-8\n    expected_pct = np.where(expected_pct == 0, eps, expected_pct)\n    actual_pct = np.where(actual_pct == 0, eps, actual_pct)\n\n    # Calculate PSI\n    psi = np.sum((actual_pct - expected_pct) * np.log(actual_pct / expected_pct))\n\n    return float(psi)\n</code></pre>"},{"location":"reference/#tanml.analysis.drift.calculate_ks","title":"<code>calculate_ks(expected, actual)</code>","text":"<p>Calculate Kolmogorov-Smirnov statistic between two distributions.</p> <p>Parameters:</p> Name Type Description Default <code>expected</code> <code>Series</code> <p>Expected/baseline distribution</p> required <code>actual</code> <code>Series</code> <p>Actual/new distribution</p> required <p>Returns:</p> Type Description <code>tuple[float, float]</code> <p>Tuple of (KS statistic, p-value)</p> Source code in <code>tanml/analysis/drift.py</code> <pre><code>def calculate_ks(\n    expected: pd.Series,\n    actual: pd.Series,\n) -&gt; tuple[float, float]:\n    \"\"\"\n    Calculate Kolmogorov-Smirnov statistic between two distributions.\n\n    Args:\n        expected: Expected/baseline distribution\n        actual: Actual/new distribution\n\n    Returns:\n        Tuple of (KS statistic, p-value)\n    \"\"\"\n    from scipy import stats\n\n    expected = expected.dropna()\n    actual = actual.dropna()\n\n    if len(expected) == 0 or len(actual) == 0:\n        return np.nan, np.nan\n\n    try:\n        ks_stat, p_value = stats.ks_2samp(expected, actual)\n        return float(ks_stat), float(p_value)\n    except Exception:\n        return np.nan, np.nan\n</code></pre>"},{"location":"reference/#tanml.analysis.drift.analyze_drift","title":"<code>analyze_drift(train_df, test_df, numeric_cols=None, psi_threshold=0.1, ks_threshold=0.05)</code>","text":"<p>Analyze feature drift between training and test datasets.</p> <p>Parameters:</p> Name Type Description Default <code>train_df</code> <code>DataFrame</code> <p>Training dataset</p> required <code>test_df</code> <code>DataFrame</code> <p>Test dataset</p> required <code>numeric_cols</code> <code>list[str] | None</code> <p>List of numeric columns to analyze (auto-detected if None)</p> <code>None</code> <code>psi_threshold</code> <code>float</code> <p>PSI threshold for flagging drift</p> <code>0.1</code> <code>ks_threshold</code> <code>float</code> <p>KS p-value threshold for flagging drift</p> <code>0.05</code> <p>Returns:</p> Type Description <code>dict[str, dict[str, Any]]</code> <p>Dictionary with drift metrics for each column:</p> <code>dict[str, dict[str, Any]]</code> <p>{ \"column_name\": {     \"psi\": float,     \"ks_statistic\": float,     \"ks_pvalue\": float,     \"has_drift\": bool,     \"drift_level\": \"none\" | \"moderate\" | \"severe\" }</p> <code>dict[str, dict[str, Any]]</code> <p>}</p> Source code in <code>tanml/analysis/drift.py</code> <pre><code>def analyze_drift(\n    train_df: pd.DataFrame,\n    test_df: pd.DataFrame,\n    numeric_cols: list[str] | None = None,\n    psi_threshold: float = 0.1,\n    ks_threshold: float = 0.05,\n) -&gt; dict[str, dict[str, Any]]:\n    \"\"\"\n    Analyze feature drift between training and test datasets.\n\n    Args:\n        train_df: Training dataset\n        test_df: Test dataset\n        numeric_cols: List of numeric columns to analyze (auto-detected if None)\n        psi_threshold: PSI threshold for flagging drift\n        ks_threshold: KS p-value threshold for flagging drift\n\n    Returns:\n        Dictionary with drift metrics for each column:\n        {\n            \"column_name\": {\n                \"psi\": float,\n                \"ks_statistic\": float,\n                \"ks_pvalue\": float,\n                \"has_drift\": bool,\n                \"drift_level\": \"none\" | \"moderate\" | \"severe\"\n            }\n        }\n    \"\"\"\n    if numeric_cols is None:\n        numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n\n    # Get common columns\n    common_cols = [c for c in numeric_cols if c in train_df.columns and c in test_df.columns]\n\n    results = {}\n    for col in common_cols:\n        psi = calculate_psi(train_df[col], test_df[col])\n        ks_stat, ks_pval = calculate_ks(train_df[col], test_df[col])\n\n        # Determine drift level\n        if np.isnan(psi):\n            drift_level = \"unknown\"\n            has_drift = False\n        elif psi &gt;= 0.2:\n            drift_level = \"severe\"\n            has_drift = True\n        elif psi &gt;= psi_threshold:\n            drift_level = \"moderate\"\n            has_drift = True\n        else:\n            drift_level = \"none\"\n            has_drift = False\n\n        results[col] = {\n            \"psi\": psi,\n            \"ks_statistic\": ks_stat,\n            \"ks_pvalue\": ks_pval,\n            \"has_drift\": has_drift,\n            \"drift_level\": drift_level,\n        }\n\n    return results\n</code></pre>"},{"location":"user-guide/getting-started/","title":"Getting Started","text":"<p>This guide walks you through the end-to-end lifecycle of a model validation project using TanML.</p>"},{"location":"user-guide/getting-started/#prerequisites","title":"Prerequisites","text":"<p>TanML requires Python 3.10 or higher. We strongly recommend using a virtual environment:</p> <pre><code># Create and activate environment\npython -m venv .venv\nsource .venv/bin/activate  # Mac/Linux\n# .venv\\Scripts\\activate   # Windows\n\n# Install TanML\npip install tanml\n</code></pre>"},{"location":"user-guide/getting-started/#the-validation-lifecycle","title":"The Validation Lifecycle","text":"<p>Launch the dashboard to begin:</p> <pre><code>tanml ui\n</code></pre>"},{"location":"user-guide/getting-started/#1-data-ingestion","title":"1. Data Ingestion","text":"<p>The first step is loading your data. TanML supports CSV and Parquet formats. - Upload: Drop your training and testing datasets into the upload area. - Target Selection: Identify the column you want to predict. TanML will automatically infer if it is a Classification or Regression task.</p>"},{"location":"user-guide/getting-started/#2-data-profiling","title":"2. Data Profiling","text":"<p>Before modeling, you must understand your distributions. - Navigate to the Profiling tab to see descriptive statistics and histograms for every feature. - Look for outliers, data quality issues, or unexpected shifts that might impact model performance.</p>"},{"location":"user-guide/getting-started/#3-preprocessing","title":"3. Preprocessing","text":"<p>TanML simplifies data cleaning for tabular ML. - Null Handling: View missing value counts and apply automated imputation (Mean/Median for numeric, Mode for categorical). - Encoding: Automatically convert categorical text into model-ready numeric formats.</p>"},{"location":"user-guide/getting-started/#4-feature-power-ranking","title":"4. Feature Power Ranking","text":"<p>Identify which features actually drive your model. - The Ranking tab uses mutual information and correlation analysis to rank features by their predictive strength. - Use this to prune \"noise\" features and focus your validation on the most influential variables.</p>"},{"location":"user-guide/getting-started/#5-benchmark-evaluation","title":"5. Benchmark &amp; Evaluation","text":"<p>Train a high-performance benchmark (XGBoost/LightGBM) to establish a baseline. - Performance: View ROC curves, Precision-Recall charts, and Confusion Matrices. - Drift: Calculate the Population Stability Index (PSI) to see if your test data has shifted away from your training data. - XAI: Generate SHAP beeswarm plots to see why the model is making specific decisions.</p>"},{"location":"user-guide/getting-started/#6-reporting","title":"6. Reporting","text":"<p>The final and most critical step for compliance. - Click Generate Report in the sidebar. - TanML programmatically builds a professional .docx file containing all charts, metrics, and data summaries. - This report is ready-to-edit for your Model Risk Management (MRM) or audit folder.</p>"},{"location":"user-guide/getting-started/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"user-guide/getting-started/#remote-access","title":"Remote Access","text":"<p>Running TanML on a powerful office server? Use the public flag: <pre><code>tanml ui --public --port 8501\n</code></pre> Note: Ensure you are on a secure VPN/network when using <code>--public</code>.</p>"},{"location":"user-guide/getting-started/#headless-mode","title":"Headless Mode","text":"<p>Running on a server without a monitor? <pre><code>tanml ui --headless\n</code></pre> This starts the backend without trying to open a local browser. You can then access it from your laptop using the server's IP address.</p>"},{"location":"user-guide/tutorials/","title":"Tutorials","text":"<p>While TanML is primarily a UI-driven tool, its core analytical engine is available as a standard Python library. This allows data scientists to integrate TanML's validation checks into notebooks or automated pipelines.</p>"},{"location":"user-guide/tutorials/#programmatic-usage-advanced","title":"Programmatic Usage (Advanced)","text":""},{"location":"user-guide/tutorials/#1-accessing-the-model-registry","title":"1. Accessing the Model Registry","text":"<p>You can access the internal factory of pre-configured models directly. This is useful for inspecting default hyperparameters or programmatically selecting algorithms.</p> <pre><code>from tanml.models.registry import list_models, build_estimator\n\n# List all available regression models\nreg_models = list_models(task=\"regression\")\nprint(f\"Available Regression Models: {list(reg_models.keys())}\")\n\n# Build a configured XGBoost Classifier\nmodel = build_estimator(\"xgboost\", \"XGBClassifier\", params={\"n_estimators\": 500})\nprint(model)\n</code></pre>"},{"location":"user-guide/tutorials/#2-calculating-data-drift-psi","title":"2. Calculating Data Drift (PSI)","text":"<p>You can use the <code>analysis</code> module to calculate Population Stability Index (PSI) or Kolmogorov-Smirnov (KS) statistics on any two pandas Series, without needing the full UI workflow.</p> <pre><code>import pandas as pd\nimport numpy as np\nfrom tanml.analysis.drift import calculate_psi\n\n# Example: Simulate training and production data\ntrain_data = pd.Series(np.random.normal(0, 1, 1000))\nprod_data = pd.Series(np.random.normal(0.5, 1, 1000)) # Shifted mean\n\n# Calculate PSI\npsi = calculate_psi(train_data, prod_data)\n\nprint(f\"Population Stability Index: {psi:.4f}\")\n\nif psi &gt; 0.2:\n    print(\"\ud83d\udea8 Critical Drift Detected!\")\nelse:\n    print(\"\u2705 Distribution is stable.\")\n</code></pre>"},{"location":"user-guide/tutorials/#3-check-explained-variance-vif","title":"3. Check Explained Variance (VIF)","text":"<p>Detect multicollinearity in your feature set programmatically.</p> <pre><code>from tanml.analysis.correlation import calculate_vif\n\ndf = pd.DataFrame({\n    \"f1\": np.random.rand(100),\n    \"f2\": np.random.rand(100)\n})\n# Create a collinear feature\ndf[\"f3\"] = df[\"f1\"] * 2 + 0.5 \n\nvif_report = calculate_vif(df)\nprint(f\"High VIF Features: {vif_report['high_vif_features']}\")\n</code></pre>"}]}